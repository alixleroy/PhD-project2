'''
Implementation of weighted delayed acceptance sampling algorithm for the double-glazing inverse problem. Referece paper: "Markov Chain Monte Carlo Using 
an Approximation" by J. AndrÃ©s Christen and Colin Fox
'''

from fenics import *
import numpy as np

from Master_Solver import master_solver
from Stretch_Mesh import stretch_mesh
from Time_Stepping import time_organiser

def log_ratio(#y,
              #u1,
              #u2,
              alpha1,
              alpha2,
              sigma_p,
              sigma_l,
              mu_p,
              f1_norm,
              f2_norm
              ):
    '''
    Calculate the log acceptance ratio between mesh point values using L2 norm.

    Inputs:
        alpha1:         Float:      First alpha value for comparison.
        alpha2:         Float:      Second alpha value for comaprison.
        sigma_p:        Float:      Variance of Gaussian prior density.
        sigma_l:        Float:      Variance used in likelihood function.
        mu_p:           Float:      Mean of Gaussian prior density.
        f1_norm:        Float:      L2 norm between data and solution generated with alpha1.
        f2_norm:        Float:      L2 norm between data and solution generated with alpha2.
    Outpus:
        log_ratio:      Float:      Natural log of ratio of likelihoods, used in acceptance.
    '''
    log_ratio = 0.5 * ((((alpha1 - mu_p) ** 2 - (alpha2 - mu_p) ** 2) / sigma_p ** 2) + (f1_norm ** 2 - f2_norm ** 2)/ sigma_l ** 2)
    
    return log_ratio

def A_mat(u):
    '''
    Format u into correct shape.
    '''
    return u

def A_mat_coarse(u):
    '''
    Format u into correct shape (coarse edition).
    '''
    return u

def delayed_acceptance(alpha0,
                       y,
                       y_coarse,
                       coarsening,
                       sigma_q, 
                       sigma_p,
                       sigma_l,
                       mu_p,
                       nx,
                       tau,
                       epsilon,
                       iterations,
                       num_steps,
                       num_steps_coarse,
                       dt_min,
                       dt_max,
                       reg
                       ):
    '''
    Carries out iterations of the delayed acceptance algorithm using likelihood estimator. Based on RWMH, this algorithm aims to decrease the sampling time
    by first using a cheaper-to-compute approximation of the likelihood, and only computing the full likelihood after acceptance.

    Inputs:
        alpha0:         Float:      Initial value for alpha.
        y:              np.Array:   Generated data encoding information about heat distribution in time.
        y_coarse:       np.Array:   y projected onto coarser grid.
        coarsening:     Int:        Size of coarse grid (square).
        sigma_q:        Float:      Variance of proposal distribution (stepsize).
        sigma_p:        Float:      Variance of prior distribution. 
        sigma_l:        Float:      Variance used in likelihood caluclation (hyperparameter).
        mu_p:           Float:      Mean of prior distribution.
        nx:             Int:        Size of fine mesh (must be square, nx=ny).
        tau:            Float:      Rate of growth of hot wall boundary.
        epsilon:        Float:      Diffusion coefficient from advection-diffusion equation.
        iterations:     Int:        Desired number of iterations for delayed acceptance alogorithm.
        num_steps:      Int:        Number of steps in time calculated by the double-glazing solver.
        dt_min:         Float:      Initial timestepping value (variable time-stepping).
        dt_max:         Float:      Limit of dt (variable time-stepping)
        reg:            Float:      Regularisation constant used in variable time-stepping (hyperparameter)
    Outpus:
        alpha_list:     List:       List of samples for alpha generated by delayed acceptance algorithm.
    '''

    mesh = stretch_mesh(nx=nx, ny=nx)
    mesh_coarse = stretch_mesh(nx=coarsening, ny=coarsening)
    
    alpha_list = [alpha0]
    alpha1 = alpha0

    ### TESTING ###
    likelihood_list = []
    likelihood_coarse_list = []

    u1, __ = master_solver(mesh,
                           tau,
                           alpha1,
                           epsilon,
                           num_steps,
                           dt_min,
                           dt_max,
                           reg
                           )

    u1_coarse, __ = master_solver(mesh_coarse,
                                  tau,
                                  alpha1,
                                  epsilon,
                                  num_steps_coarse,
                                  dt_min,
                                  dt_max,
                                  reg
                                  )

    u1_norm = np.linalg.norm(y - A_mat(u1))
    u1_coarse_norm = np.linalg.norm(y_coarse - A_mat(u1_coarse))

    for i in range(iterations):

        alpha2 = np.random.normal(alpha1, sigma_q)

        u2_coarse, __ = master_solver(mesh_coarse,
                                      tau,
                                      alpha2,
                                      epsilon,
                                      num_steps_coarse,
                                      dt_min,
                                      dt_max,
                                      reg
                                      )

        u2_coarse_norm = np.linalg.norm(y_coarse - A_mat_coarse(u2_coarse))

        A_coarse = log_ratio(#y,
                             #u1,
                             #u2,
                             alpha1,
                             alpha2,
                             sigma_p,
                             sigma_l,
                             mu_p,
                             u1_coarse_norm,
                             u2_coarse_norm
                             )

        if A_coarse >= 0 or np.log(np.random.uniform(0,1)) <= A_coarse:

            u2, __ = master_solver(mesh,
                                   tau,
                                   alpha2,
                                   epsilon,
                                   num_steps,
                                   dt_min,
                                   dt_max,
                                   reg
                                   )

            u2_norm = np.linalg.norm(y - A_mat(u2))

            A = log_ratio(#y,
                          #u1,
                          #u2,
                          alpha1,
                          alpha2,
                          sigma_p,
                          sigma_l,
                          mu_p,
                          u1_norm,
                          u2_norm
                          )
            
            if A >= 0 or np.log(np.random.uniform(0,1)) <= A + min(0, A_coarse):  ############################# THINK ABOUT THIS!!!!!! ######################################
                
                alpha1 = alpha2

                u1 = u2
                u1_coarse = u2_coarse
                u1_norm = u2_norm
                u1_coarse_norm = u2_coarse_norm

                ### TESTING ###
                likelihood_list.append(u2_norm)
                likelihood_coarse_list.append(u2_coarse_norm)
            
            else: 

                print('rejected second')
        
        else:

            print('rejected first')

        alpha_list.append(alpha1)

        print(i)

    return(alpha_list,
           likelihood_list,
           likelihood_coarse_list)


if __name__ == "__main__":

    import pickle 

    def main():

        # Solver parameters.
        alpha0 = 2
        tau = 1/10
        epsilon = 1/100
        num_steps = 60
        nx = 32
        dt_min = 1e-3
        dt_max = 0.1
        reg = 10

        # MCMC parameters.
        iterations = 100
        sigma_q = 0.1
        sigma_p = 1
        mu_p = 0
        sigma_l = 0.2

        # Delayed accpetance parameters.
        coarsening = 16 
        num_steps_coarse = 40

        # Data augmentation.
        alpha_star = 0
        var_noise = 0.3

        with open(f'Master/Data_eps100_num150000_tau10_alpha0/master_data_{nx}_project', 'rb') as file:
            y_star = pickle.load(file)
        
        with open(f'Master/Data_eps100_num150000_tau10_alpha0/master_data_{coarsening}_project', 'rb') as file:
            y_coarse_star = pickle.load(file)
        
        y_star_thinned = time_organiser(y_star,
                                        dt_min,
                                        dt_max,
                                        tau,
                                        reg,
                                        num_steps
                                        )[:-1] # Make removing last element more elegant!
        
        y_coarse_star_thinned = time_organiser(y_coarse_star,
                                               dt_min,
                                               dt_max,
                                               tau,
                                               reg,
                                               num_steps_coarse
                                               )[:-1] # Make removing last element more elegant!


        # mesh = stretch_mesh(nx=nx, ny=ny)

        # y_star_coarse, __ = master_solver(#nx,
        #                                   #ny,
        #                                   mesh,
        #                                   tau,
        #                                   alpha_star,
        #                                   epsilon,
        #                                   num_steps,
        #                                   dt_min,
        #                                   dt_max,
        #                                   reg
        #                                   )

        noise = np.random.normal(0, var_noise, np.shape(y_star_thinned))
        y = y_star_thinned + noise
        y_coarse = y_coarse_star_thinned + noise[:len(y_coarse_star_thinned),:len(y_coarse_star[0])] ### this is not proper!!!!!!!!!!!!!!!!!!!!!!!!!!!!

        #+ np.random.normal(np.zeros(np.shape(y_star)), var_noise)

        alpha_list, likelihood_list, likelihood_coarse_list = delayed_acceptance(alpha0,
                                                                                 y,
                                                                                 y_coarse,
                                                                                 coarsening, 
                                                                                 sigma_q, 
                                                                                 sigma_p,
                                                                                 sigma_l,
                                                                                 mu_p,
                                                                                 nx,
                                                                                 tau,
                                                                                 epsilon,
                                                                                 iterations,
                                                                                 num_steps,
                                                                                 num_steps_coarse,
                                                                                 dt_min,
                                                                                 dt_max,
                                                                                 reg
                                                                                 )

        return(alpha_list,
               likelihood_list,
               likelihood_coarse_list)
    
    print(main())
